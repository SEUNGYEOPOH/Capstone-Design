{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7c1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\python_code\\Capstone\\sm\\segmentation_model\n"
     ]
    }
   ],
   "source": [
    "%cd segmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d037ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"/device:GPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52354097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F6F4727EB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Area: 16.36664563651708 square meters\n"
     ]
    }
   ],
   "source": [
    "from tools.img_tools import *\n",
    "from tools.preprocessing import *\n",
    "from tools.augmentation import *\n",
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "import segmentation_models as sm\n",
    "import cv2\n",
    "\n",
    "BACKBONE = 'efficientnetb3'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "n_classes = 3\n",
    "\n",
    "model = sm.Unet(BACKBONE, classes=n_classes)\n",
    "model.load_weights('best_model1.h5')\n",
    "\n",
    "# datadir = './img/'\n",
    "# xtd = os.path.join(datadir, 'test')\n",
    "# file = os.listdir(xtd)\n",
    "\n",
    "img = cv2.imread('./video/cap/0.png')\n",
    "\n",
    "test_dataset = test_Dataset(\n",
    "    img, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    ")\n",
    "\n",
    "image = test_dataset[0]\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "pr_mask = model.predict(image).round()\n",
    "\n",
    "road = pr_mask[...,0].squeeze()\n",
    "pavement = pr_mask[...,1].squeeze()\n",
    "\n",
    "mask_arr = road + pavement\n",
    "mask_arr = np.where((mask_arr)>0,255,0)\n",
    "\n",
    "mask = Image.fromarray(mask_arr)\n",
    "mask.show()\n",
    "mask.save('./img/label/0.png')\n",
    "# mask_arr = np.array(mask)\n",
    "# cv_img = cv2.cvtColor(mask_arr, cv2.COLOR_RGB2BGR)\n",
    "# cv2.imshow('',cv_img)\n",
    "\n",
    "# dpi = img.info['dpi']\n",
    "# mask = mask.resize([1440,1080])\n",
    "area = measure(mask, dpi=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94729bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Area: 69.04788003124393 square meters\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Area: 70.67562522221819 square meters\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"./video/test_video.mp4\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter('output.mp4',fourcc, 20.0, (480,360))\n",
    "\n",
    "BACKBONE = 'efficientnetb3'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "n_classes = 3\n",
    "\n",
    "model = sm.Unet(BACKBONE, classes=n_classes)\n",
    "model.load_weights('best_model1.h5')\n",
    "\n",
    "i=0\n",
    "road_area = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.resize(frame, (480, 360))\n",
    "    frame = cv2.putText(frame, f'AREA: {road_area}m', (235,350), cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                       (0,0,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('video',frame)\n",
    "    \n",
    "    if(int(cap.get(1)) % (fps*1.5) == 0):\n",
    "#         image = Image.fromarray(frame)\n",
    "#         image.save(f\"./cap/{i}.png\", 'png')\n",
    "        cv2.imwrite(f'./video/cap/{i}.png', frame)\n",
    "#         fr = Image.open(f\"./video/cap/{i}.png\")\n",
    "        fr = cv2.imread(f'./video/cap/{i}.png')\n",
    "\n",
    "        test_dataset = test_Dataset(\n",
    "            fr, \n",
    "            augmentation=get_validation_augmentation(),\n",
    "            preprocessing=get_preprocessing(preprocess_input)\n",
    "        )\n",
    "\n",
    "        image = test_dataset[0]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        pr_mask = model.predict(image).round()\n",
    "\n",
    "        road = pr_mask[...,0].squeeze()\n",
    "        pavement = pr_mask[...,1].squeeze()\n",
    "\n",
    "        mask_arr = road + pavement\n",
    "        mask_arr = np.where((mask_arr)>0,255,0)\n",
    "\n",
    "        mask = Image.fromarray(mask_arr)\n",
    "        area = round(measure(mask, dpi=10),2)\n",
    "        \n",
    "        if road_area < area:\n",
    "            road_area = area\n",
    "        \n",
    "        mask.save('./img/label/0.png') # PIL로 이미지 저장하면 cv2나 뷰어로 확인시 검정색만 뜸\n",
    "        # 이유는 벡터를 이미지로 변환하는 방식이 달라서\n",
    "        mask = cv2.imread(f'./video/output/{i}.png')\n",
    "        \n",
    "        i+=1\n",
    "#         cv2.imshow('mask',mask)\n",
    "    \n",
    "#     out.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'capstone'",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
