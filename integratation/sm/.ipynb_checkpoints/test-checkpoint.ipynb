{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7c1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\python_code\\Capstone\\sm\\segmentation_model\n"
     ]
    }
   ],
   "source": [
    "%cd segmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d037ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"/device:GPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9a31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "import tools.segmentation_models as sm\n",
    "from tools.img_tools import *\n",
    "from tools.train_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e182ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\albumentations\\augmentations\\transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\albumentations\\augmentations\\transforms.py:1175: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\python_code\\Capstone\\sm\\segmentation_model\\tools\\train_model.py:329: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 29s 194ms/step - loss: 0.6168 - iou_score: 0.4594 - f1-score: 0.5572 - val_loss: 0.1535 - val_iou_score: 0.8033 - val_f1-score: 0.8779 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "91/91 [==============================] - 16s 178ms/step - loss: 0.3519 - iou_score: 0.6639 - f1-score: 0.7623 - val_loss: 0.0765 - val_iou_score: 0.8548 - val_f1-score: 0.9163 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "91/91 [==============================] - 17s 181ms/step - loss: 0.2576 - iou_score: 0.6773 - f1-score: 0.7772 - val_loss: 0.0303 - val_iou_score: 0.8549 - val_f1-score: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "91/91 [==============================] - 16s 181ms/step - loss: 0.1916 - iou_score: 0.7177 - f1-score: 0.8087 - val_loss: -0.0014 - val_iou_score: 0.8631 - val_f1-score: 0.9217 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "91/91 [==============================] - 21s 233ms/step - loss: 0.1669 - iou_score: 0.7255 - f1-score: 0.8158 - val_loss: -0.0655 - val_iou_score: 0.9125 - val_f1-score: 0.9519 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "91/91 [==============================] - 20s 219ms/step - loss: 0.1386 - iou_score: 0.7374 - f1-score: 0.8268 - val_loss: -0.0120 - val_iou_score: 0.8678 - val_f1-score: 0.9230 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "91/91 [==============================] - 20s 223ms/step - loss: 0.1204 - iou_score: 0.7492 - f1-score: 0.8360 - val_loss: -0.0462 - val_iou_score: 0.8957 - val_f1-score: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "91/91 [==============================] - 20s 221ms/step - loss: 0.1049 - iou_score: 0.7519 - f1-score: 0.8400 - val_loss: -0.0614 - val_iou_score: 0.9048 - val_f1-score: 0.9472 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "91/91 [==============================] - 20s 222ms/step - loss: 0.0860 - iou_score: 0.7735 - f1-score: 0.8540 - val_loss: -0.0527 - val_iou_score: 0.8992 - val_f1-score: 0.9436 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "91/91 [==============================] - 21s 230ms/step - loss: 0.0823 - iou_score: 0.7659 - f1-score: 0.8501 - val_loss: -0.0822 - val_iou_score: 0.9222 - val_f1-score: 0.9575 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "91/91 [==============================] - 22s 236ms/step - loss: 0.0794 - iou_score: 0.7740 - f1-score: 0.8545 - val_loss: -0.0383 - val_iou_score: 0.8889 - val_f1-score: 0.9367 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "91/91 [==============================] - 21s 227ms/step - loss: 0.0611 - iou_score: 0.7831 - f1-score: 0.8632 - val_loss: -0.0900 - val_iou_score: 0.9285 - val_f1-score: 0.9614 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "91/91 [==============================] - 21s 227ms/step - loss: 0.0607 - iou_score: 0.7838 - f1-score: 0.8622 - val_loss: -0.0307 - val_iou_score: 0.8814 - val_f1-score: 0.9325 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "91/91 [==============================] - 21s 229ms/step - loss: 0.0668 - iou_score: 0.7762 - f1-score: 0.8573 - val_loss: -0.0529 - val_iou_score: 0.8976 - val_f1-score: 0.9424 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "91/91 [==============================] - 20s 217ms/step - loss: 0.0486 - iou_score: 0.7904 - f1-score: 0.8688 - val_loss: -0.0429 - val_iou_score: 0.8896 - val_f1-score: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "91/91 [==============================] - 19s 210ms/step - loss: 0.0596 - iou_score: 0.7770 - f1-score: 0.8586 - val_loss: -0.0613 - val_iou_score: 0.9044 - val_f1-score: 0.9469 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "91/91 [==============================] - 21s 230ms/step - loss: 0.0573 - iou_score: 0.7837 - f1-score: 0.8619 - val_loss: -0.0582 - val_iou_score: 0.9027 - val_f1-score: 0.9455 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "91/91 [==============================] - 20s 219ms/step - loss: 0.0496 - iou_score: 0.7813 - f1-score: 0.8630 - val_loss: -0.0676 - val_iou_score: 0.9088 - val_f1-score: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "91/91 [==============================] - 20s 218ms/step - loss: 0.0716 - iou_score: 0.7722 - f1-score: 0.8544 - val_loss: -0.0869 - val_iou_score: 0.9253 - val_f1-score: 0.9594 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "91/91 [==============================] - 20s 221ms/step - loss: 0.0446 - iou_score: 0.7919 - f1-score: 0.8693 - val_loss: -0.0996 - val_iou_score: 0.9365 - val_f1-score: 0.9661 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "91/91 [==============================] - 21s 224ms/step - loss: 0.0492 - iou_score: 0.7878 - f1-score: 0.8658 - val_loss: -0.0667 - val_iou_score: 0.9092 - val_f1-score: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "91/91 [==============================] - 20s 220ms/step - loss: 0.0303 - iou_score: 0.7985 - f1-score: 0.8745 - val_loss: -0.0951 - val_iou_score: 0.9318 - val_f1-score: 0.9635 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "91/91 [==============================] - 20s 213ms/step - loss: 0.0344 - iou_score: 0.8022 - f1-score: 0.8759 - val_loss: -0.0991 - val_iou_score: 0.9354 - val_f1-score: 0.9655 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "91/91 [==============================] - 21s 224ms/step - loss: 0.0311 - iou_score: 0.8025 - f1-score: 0.8786 - val_loss: -0.0897 - val_iou_score: 0.9279 - val_f1-score: 0.9613 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "91/91 [==============================] - 19s 210ms/step - loss: 0.0348 - iou_score: 0.8001 - f1-score: 0.8744 - val_loss: -0.0891 - val_iou_score: 0.9272 - val_f1-score: 0.9608 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "91/91 [==============================] - 22s 243ms/step - loss: 0.0133 - iou_score: 0.8170 - f1-score: 0.8870 - val_loss: -0.1028 - val_iou_score: 0.9391 - val_f1-score: 0.9676 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "91/91 [==============================] - 20s 219ms/step - loss: 0.0160 - iou_score: 0.8062 - f1-score: 0.8806 - val_loss: -0.1015 - val_iou_score: 0.9380 - val_f1-score: 0.9668 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "91/91 [==============================] - 21s 231ms/step - loss: 0.0141 - iou_score: 0.8158 - f1-score: 0.8865 - val_loss: -0.1057 - val_iou_score: 0.9419 - val_f1-score: 0.9691 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "91/91 [==============================] - 21s 225ms/step - loss: 0.0125 - iou_score: 0.8169 - f1-score: 0.8891 - val_loss: -0.0894 - val_iou_score: 0.9276 - val_f1-score: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "91/91 [==============================] - 20s 220ms/step - loss: 0.0248 - iou_score: 0.8104 - f1-score: 0.8853 - val_loss: -0.0784 - val_iou_score: 0.9172 - val_f1-score: 0.9555 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "91/91 [==============================] - 20s 220ms/step - loss: 0.0180 - iou_score: 0.8156 - f1-score: 0.8850 - val_loss: -0.0782 - val_iou_score: 0.9179 - val_f1-score: 0.9555 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "91/91 [==============================] - 20s 222ms/step - loss: 0.0111 - iou_score: 0.8150 - f1-score: 0.8861 - val_loss: -0.0863 - val_iou_score: 0.9251 - val_f1-score: 0.9597 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "91/91 [==============================] - 20s 217ms/step - loss: 0.0186 - iou_score: 0.8144 - f1-score: 0.8844 - val_loss: -0.0803 - val_iou_score: 0.9203 - val_f1-score: 0.9568 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "91/91 [==============================] - 21s 225ms/step - loss: 0.0204 - iou_score: 0.8135 - f1-score: 0.8863 - val_loss: -0.0746 - val_iou_score: 0.9156 - val_f1-score: 0.9539 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "91/91 [==============================] - 22s 238ms/step - loss: 0.0110 - iou_score: 0.8177 - f1-score: 0.8879 - val_loss: -0.0913 - val_iou_score: 0.9290 - val_f1-score: 0.9619 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "91/91 [==============================] - 22s 236ms/step - loss: 0.0056 - iou_score: 0.8230 - f1-score: 0.8914 - val_loss: -0.0940 - val_iou_score: 0.9310 - val_f1-score: 0.9631 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "91/91 [==============================] - 21s 232ms/step - loss: 0.0041 - iou_score: 0.8173 - f1-score: 0.8881 - val_loss: -0.0688 - val_iou_score: 0.9114 - val_f1-score: 0.9513 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "91/91 [==============================] - 21s 228ms/step - loss: 0.0092 - iou_score: 0.8169 - f1-score: 0.8876 - val_loss: -0.0802 - val_iou_score: 0.9200 - val_f1-score: 0.9566 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "91/91 [==============================] - 21s 227ms/step - loss: 0.0095 - iou_score: 0.8106 - f1-score: 0.8836 - val_loss: -0.0811 - val_iou_score: 0.9212 - val_f1-score: 0.9572 - lr: 1.0000e-05\n",
      "Epoch 40/40\n",
      "91/91 [==============================] - 21s 228ms/step - loss: -0.0032 - iou_score: 0.8212 - f1-score: 0.8914 - val_loss: -0.0828 - val_iou_score: 0.9225 - val_f1-score: 0.9580 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\python_code\\Capstone\\sm\\segmentation_model\\tools\\train_model.py:339: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scores = model.evaluate_generator(test_dataloader)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.01899\n",
      "mean iou_score: 0.87348\n",
      "mean f1-score: 0.92451\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './data/CamVid/'\n",
    "\n",
    "x_train = os.path.join(DATA_DIR, 'train')\n",
    "y_train = os.path.join(DATA_DIR, 'trainannot')\n",
    "\n",
    "x_valid = os.path.join(DATA_DIR, 'val')\n",
    "y_valid = os.path.join(DATA_DIR, 'valannot')\n",
    "\n",
    "x_test = os.path.join(DATA_DIR, 'test')\n",
    "y_test = os.path.join(DATA_DIR, 'testannot')\n",
    "\n",
    "area_segmentation(x_train, y_train, x_valid, y_valid, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94729bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./video/test_video.mp4\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter('output.mp4',fourcc, 20.0, (480,360))\n",
    "\n",
    "BACKBONE = 'efficientnetb3'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "n_classes = 3\n",
    "\n",
    "model = sm.Unet(BACKBONE, classes=n_classes)\n",
    "model.load_weights('best_model1.h5')\n",
    "\n",
    "i=0\n",
    "road_area = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.resize(frame, (480, 360))\n",
    "    frame = cv2.putText(frame, f'AREA: {road_area}m', (235,350), cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                       (0,0,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('video',frame)\n",
    "    \n",
    "    if(int(cap.get(1)) % (fps*1.5) == 0):\n",
    "#         image = Image.fromarray(frame)\n",
    "#         image.save(f\"./cap/{i}.png\", 'png')\n",
    "        \n",
    "        cv2.imwrite(f'./video/cap/{i}.png', frame)\n",
    "#         fr = Image.open(f\"./video/cap/{i}.png\")\n",
    "        fr = cv2.imread(f'./video/cap/{i}.png')\n",
    "\n",
    "        test_dataset = predict_Dataset(\n",
    "            fr, \n",
    "            augmentation=get_validation_augmentation(),\n",
    "            preprocessing=get_preprocessing(preprocess_input)\n",
    "        )\n",
    "\n",
    "        image = test_dataset[0]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        pr_mask = model.predict(image).round()\n",
    "\n",
    "        road = pr_mask[...,0].squeeze()\n",
    "        pavement = pr_mask[...,1].squeeze()\n",
    "\n",
    "        mask_arr = road + pavement\n",
    "        mask_arr = np.where((mask_arr)>0,255,0)\n",
    "\n",
    "        mask = Image.fromarray(mask_arr)\n",
    "        \n",
    "        area = round(measure(mask, dpi=10),2)\n",
    "        \n",
    "        if road_area < area:\n",
    "            road_area = area\n",
    "        \n",
    "        mask.save('./img/label/0.png') # PIL로 이미지 저장하면 cv2나 뷰어로 확인시 검정색만 뜸\n",
    "        # 이유는 벡터를 이미지로 변환하는 방식이 달라서\n",
    "        mask = cv2.imread(f'./video/output/{i}.png')\n",
    "        \n",
    "        i+=1\n",
    "#         cv2.imshow('mask',mask)\n",
    "    \n",
    "#     out.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52354097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BACKBONE = 'efficientnetb3'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "n_classes = 3\n",
    "\n",
    "model = sm.Unet(BACKBONE, classes=n_classes)\n",
    "model.load_weights('best_model_segmentation.h5')\n",
    "\n",
    "# datadir = './img/'\n",
    "# xtd = os.path.join(datadir, 'test')\n",
    "# file = os.listdir(xtd)\n",
    "\n",
    "img = cv2.imread('./video/cap/0.png')\n",
    "\n",
    "test_dataset = predict_Dataset(\n",
    "    img, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    ")\n",
    "\n",
    "image = test_dataset[0]\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "pr_mask = model.predict(image).round()\n",
    "\n",
    "road = pr_mask[...,0].squeeze()\n",
    "pavement = pr_mask[...,1].squeeze()\n",
    "\n",
    "mask_arr = road + pavement\n",
    "mask_arr = np.where((mask_arr)>0,255,0)\n",
    "\n",
    "mask = Image.fromarray(mask_arr)\n",
    "mask.show()\n",
    "mask.save('./img/label/0.png')\n",
    "# mask_arr = np.array(mask)\n",
    "# cv_img = cv2.cvtColor(mask_arr, cv2.COLOR_RGB2BGR)\n",
    "# cv2.imshow('',cv_img)\n",
    "\n",
    "# dpi = img.info['dpi']\n",
    "# mask = mask.resize([1440,1080])\n",
    "area = measure(mask, dpi=20)\n",
    "area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'capstone'",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
